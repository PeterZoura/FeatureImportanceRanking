{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('D:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\data\\data2.tsv', delimiter=\"\\t\", index_col= 0)\n",
    "data = pd.read_csv('../data\\data2.tsv', delimiter=\"\\t\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Length  #Uppers  #Lowers  #Numbers  #Symbols  SLG_uppers  SLG_lowers  \\\n",
      "0       9        0        2         7         0           0           2   \n",
      "1      16        5        8         3         0           2           3   \n",
      "2      12        0       11         1         0           0          11   \n",
      "3       7        0        6         1         0           0           4   \n",
      "4      10        0        4         6         0           0           4   \n",
      "\n",
      "   SLG_numbers  SLG_symbols  FCT_Up  FCT_Lo  FCT_Nu  FCT_Sy  LCT_Up  LCT_Lo  \\\n",
      "0            7            0       0       0       1       0       0       1   \n",
      "1            2            0       0       1       0       0       1       0   \n",
      "2            1            0       0       1       0       0       0       0   \n",
      "3            1            0       0       1       0       0       0       1   \n",
      "4            6            0       0       1       0       0       0       0   \n",
      "\n",
      "   LCT_Nu  LCT_Sy  #words  ave_size_of_words  palindrome  \n",
      "0       0       0       0               0.00           0  \n",
      "1       0       0       0               0.00           0  \n",
      "2       1       0       4               3.25           0  \n",
      "3       0       0       0               0.00           0  \n",
      "4       1       0       2               3.50           0   \n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: Strength, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Strength','Password'], axis= 1)\n",
    "print(X.head(), \"\\n\\n---\\n\\n\")\n",
    "y = data['Strength']\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_space={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200],\n",
    "              'max_features':[1,3,5,7],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'min_samples_split':[1,2,3]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "432 fits failed out of a total of 1296.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "432 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\env\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"d:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\env\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"d:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Projects\\PasswordFeaturesComp4730AbrahamlingamDagatiZoura\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.79588009 0.81504044 0.82604053\n",
      " 0.8450399  0.83672018 0.83324058        nan        nan        nan\n",
      " 0.8235596  0.82040051 0.8144802  0.81440091 0.82636023 0.82492071\n",
      "        nan        nan        nan 0.81004003 0.82684007 0.8309201\n",
      " 0.86075709 0.82191951 0.82243968        nan        nan        nan\n",
      " 0.96828054 0.96384079 0.97432004 0.97444024 0.97572002 0.97675998\n",
      "        nan        nan        nan 0.97060005 0.97448    0.97559999\n",
      " 0.98243989 0.97575989 0.97451998        nan        nan        nan\n",
      " 0.92755766 0.97440005 0.977      0.94495862 0.9690006  0.97460003\n",
      "        nan        nan        nan 0.99376012 0.99011996 0.98999998\n",
      " 0.9657591  0.99040001 0.99032           nan        nan        nan\n",
      " 0.99076    0.98972001 0.99012002 0.98476035 0.99047998 0.9896\n",
      "        nan        nan        nan 0.98399987 0.9863203  0.99028001\n",
      " 0.96987923 0.98676025 0.98988001        nan        nan        nan\n",
      " 0.99643992 0.99839998 0.99379987 0.98376032 0.99604013 0.99588002\n",
      "        nan        nan        nan 0.99199982 0.99555986 0.99527992\n",
      " 0.99340005 0.99480013 0.99567998        nan        nan        nan\n",
      " 0.99620026 0.99456015 0.99432005 0.99656009 0.99676    0.99659989\n",
      "        nan        nan        nan 0.9275592  0.94176016 0.96551978\n",
      " 0.93743863 0.96171999 0.96828037        nan        nan        nan\n",
      " 0.90479985 0.95332017 0.95020014 0.90428159 0.96551967 0.94555945\n",
      "        nan        nan        nan 0.94107865 0.922041   0.96003976\n",
      " 0.91347774 0.94708067 0.92647979        nan        nan        nan\n",
      " 0.99235975 0.99924001 0.9998     0.99495987 0.99544029 0.99951999\n",
      "        nan        nan        nan 0.99776014 0.99923999 0.99895997\n",
      " 0.99220042 0.99751993 0.99875996        nan        nan        nan\n",
      " 0.99296028 0.99876003 0.99936    0.99480008 0.99843996 0.99920001\n",
      "        nan        nan        nan 0.99992    1.         1.\n",
      " 0.99967999 1.         1.                nan        nan        nan\n",
      " 0.99963999 0.99996    0.99996    0.99992    0.99996    1.\n",
      "        nan        nan        nan 0.99932002 0.99992    0.99996\n",
      " 0.99980002 1.         0.99992001        nan        nan        nan\n",
      " 1.         1.         1.         0.99996    1.         1.\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.99980001 1.         1.                nan        nan        nan\n",
      " 0.99992    1.         1.         1.         1.         1.\n",
      "        nan        nan        nan 0.99888002 0.99968    0.99964001\n",
      " 0.99908001 0.99968001 0.99968001        nan        nan        nan\n",
      " 0.99556003 0.99871999 0.99915999 0.99803996 0.99912001 0.99903999\n",
      "        nan        nan        nan 0.99479994 0.99815999 0.99823998\n",
      " 0.99471988 0.99832    0.99815998        nan        nan        nan\n",
      " 0.99992    1.         0.99996    0.9998     1.         1.\n",
      "        nan        nan        nan 1.         0.99988    0.99988\n",
      " 0.99968001 0.99992    0.99984           nan        nan        nan\n",
      " 0.99956001 0.99972    0.99980001 0.99976001 0.99984    0.9998\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 0.99996    1.         1.                nan        nan        nan\n",
      " 0.99992    1.         1.         0.99988    1.         1.\n",
      "        nan        nan        nan 0.9996     0.99996    0.99996\n",
      " 0.99992    0.99992    1.                nan        nan        nan\n",
      " 0.99996    1.         1.         1.         1.         1.\n",
      "        nan        nan        nan 0.99984001 1.         1.\n",
      " 0.99996    1.         1.                nan        nan        nan\n",
      " 0.99996    1.         1.         1.         1.         1.\n",
      "        nan        nan        nan 0.99896    0.99968002 0.99976001\n",
      " 0.99908002 0.99952    0.99956002        nan        nan        nan\n",
      " 0.99815999 0.999      0.99927999 0.99851999 0.99903999 0.99944\n",
      "        nan        nan        nan 0.99788004 0.99876    0.99876\n",
      " 0.99803997 0.99887998 0.99896           nan        nan        nan\n",
      " 0.99972001 0.99996    0.99996    0.99964001 1.         0.99996\n",
      "        nan        nan        nan 0.99984    0.99988    0.99984\n",
      " 0.99988    0.99984001 0.99984001        nan        nan        nan\n",
      " 0.99968002 0.99976001 0.99980001 0.99964    0.99984    0.99984\n",
      "        nan        nan        nan 0.99996    1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 0.99984001 1.         1.         0.99984001 1.         1.\n",
      "        nan        nan        nan 0.99996    1.         0.99996\n",
      " 1.         0.99996    0.99996           nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.\n",
      "        nan        nan        nan 1.         1.         1.\n",
      " 1.         1.         1.                nan        nan        nan\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "rf = RandomForestClassifier()\n",
    "grid = GridSearchCV(rf,param_grid=grid_space,cv=3,scoring='accuracy')\n",
    "model_grid = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are: {'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters are: '+str(model_grid.best_params_))\n",
    "print('Best score is: '+str(model_grid.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
